{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejercicios Clase 3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eGR2CZpmYh5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Descargo el Dataset que se dejó en Slack\n",
        "!wget clase3v2.csv https://github.com/juannieu/Desc/raw/main/c3v2.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwhig6payWSY",
        "outputId": "dc7c5b0f-61bb-4e1a-a303-0ef81ba43577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-08 12:48:51--  http://clase3v2.csv/\n",
            "Resolving clase3v2.csv (clase3v2.csv)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘clase3v2.csv’\n",
            "--2022-04-08 12:48:51--  https://github.com/juannieu/Desc/raw/main/c3v2.csv\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/juannieu/Desc/main/c3v2.csv [following]\n",
            "--2022-04-08 12:48:51--  https://raw.githubusercontent.com/juannieu/Desc/main/c3v2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16934 (17K) [text/plain]\n",
            "Saving to: ‘c3v2.csv.1’\n",
            "\n",
            "c3v2.csv.1          100%[===================>]  16.54K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-08 12:48:52 (33.2 MB/s) - ‘c3v2.csv.1’ saved [16934/16934]\n",
            "\n",
            "FINISHED --2022-04-08 12:48:52--\n",
            "Total wall clock time: 0.3s\n",
            "Downloaded: 1 files, 17K in 0s (33.2 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Ejercicio #1  Normalización**\n",
        "\n",
        "Muchos algoritmos de Machine Learning necesitan datos de entrada centrados y normalizados. Una normalización habitual es el z-score , que implica restarle la media y dividir por el desvío a cada feature de mi dataset.\n",
        "\n",
        "Dado un dataset X de n muestras y m features, implementar un método en numpy para normalizar z-score. Pueden utilizar np.mean() y np.std()."
      ],
      "metadata": {
        "id": "HXTi5M5eqSZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Utilizamos el dataset c3v2, después de haberle imputado los Nans con media, usando el código hecho para el punto 3\n",
        "#Cargamos el dataset para el punto 3\n",
        "def cargar1():\n",
        "  cam='c3v2.csv'\n",
        "  datos = pd.read_csv('c3v2.csv', sep=';'  , header=None , engine='python')\n",
        "  #print('Los datos tienen ',datos.shape[0],'filas y',datos.shape[1],'columnas')\n",
        "  #cuantosNan=np.count_nonzero(np.isnan(datos))\n",
        "  #print('Hay ',cuantosNan,' NaNs')\n",
        "  return datos\n",
        "\n",
        "def imputar_con_media(dataset_punto_3):\n",
        "  #dataset_punto_3=cargar1()\n",
        "  #print('Las medias son:', dataset_punto_3.mean())\n",
        "  medias=dataset_punto_3.mean()\n",
        "  new_dts3=dataset_punto_3.fillna(value=medias)\n",
        "  #cuantosNan3=np.count_nonzero(np.isnan(new_dts3))\n",
        "  #print('Hay ',cuantosNan3,' NaNs')\n",
        "  #print(new_dts3)\n",
        "  return medias,new_dts3\n",
        "\n",
        "def desvest(dataset_punto_3):\n",
        "  resp=np.std(dataset_punto_3,axis=1)\n",
        "  return resp\n",
        "\n",
        "d4=cargar1()\n",
        "media,imputado=imputar_con_media(d4)\n",
        "resta=imputado-media\n",
        "#Finalmente, calculamos la desviación\n",
        "desviacion=desvest(d4)\n",
        "\n",
        "respuesta=np.divide(imputado,desviacion[:,None])\n",
        "print(respuesta)\n",
        "\n"
      ],
      "metadata": {
        "id": "hveCpCC6QVIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a05db5e5-311c-4953-a555-19bf02cfd8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           0         1         2         3         4         5         6\n",
            "0   0.641753  0.500810  0.731831  0.515680 -0.110384 -1.637741  1.322948\n",
            "1   1.043301  0.346273  0.323270  0.059544 -0.048760 -0.286322  2.539064\n",
            "2  -0.634329 -0.114000  0.462698  0.100398 -0.069790  0.589645 -2.313408\n",
            "3  -0.015408  1.522675  3.336267  0.109568 -0.503217  2.710776  1.142803\n",
            "4   0.788326  0.198174  0.542596  0.096792 -0.081841 -1.489431  1.538867\n",
            "..       ...       ...       ...       ...       ...       ...       ...\n",
            "95  0.003184  0.570808  1.029698  0.281423  0.199812 -0.816947  2.649474\n",
            "96 -0.261204  0.793316  0.567010  0.468642 -0.206371 -0.532816  2.682524\n",
            "97  0.887209  0.011113  0.826640  0.209338 -0.028734 -0.123346  2.942551\n",
            "98  1.011553  0.615077  0.514379 -0.009474 -0.292146 -0.522081  2.697973\n",
            "99 -0.944264  0.135782  0.063483  0.050359 -0.080774  0.244404 -2.748348\n",
            "\n",
            "[100 rows x 7 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Ejercicio #2 Remover filas y columnas con NaNs en un dataset**\n",
        "\n",
        "Dado un dataset, hacer una función que, utilizando numpy, filtre las columnas y las filas que tienen NaNS."
      ],
      "metadata": {
        "id": "P_qKm3NurNsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos el dataset para el punto 2\n",
        "def cargar():\n",
        "  cam='c3v2.csv'\n",
        "  datos = pd.read_csv('c3v2.csv', sep=';'  , header=None , engine='python')\n",
        "  print('Los datos tienen ',datos.shape[0],'filas y',datos.shape[1],'columnas')\n",
        "  cuantosNan=np.count_nonzero(np.isnan(datos))\n",
        "  print('Hay ',cuantosNan,' NaNs')\n",
        "  return datos"
      ],
      "metadata": {
        "id": "dxV0IZE629WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Usamos la función dropna de pandas para borrar las filas y columnas con Nan\n",
        "#Borramos las Filas con Nan\n",
        "dataset=cargar()\n",
        "filas_borradas=dataset.dropna(axis=0)\n",
        "print('Los datos tienen ',dataset.shape[0],'filas y',dataset.shape[1],'columnas')\n",
        "print('Los datos tienen ',filas_borradas.shape[0],'filas y',filas_borradas.shape[1],'columnas')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF1z-noD9jG3",
        "outputId": "f8f3d9d1-fbce-45cf-9f68-d4e2f41b72f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los datos tienen  100 filas y 7 columnas\n",
            "Hay  40  NaNs\n",
            "Los datos tienen  100 filas y 7 columnas\n",
            "Los datos tienen  75 filas y 7 columnas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Borramos las Columnas con Nan\n",
        "dataset=cargar()\n",
        "columnas_borradas=dataset.dropna(axis=1)\n",
        "print('Los datos tienen ',dataset.shape[0],'filas y',dataset.shape[1],'columnas')\n",
        "print('Los datos tienen ',columnas_borradas.shape[0],'filas y',columnas_borradas.shape[1],'columnas')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-1Dgd3fLzuP",
        "outputId": "53f3a211-63b1-421b-d0aa-b11ff0ae7150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los datos tienen  100 filas y 7 columnas\n",
            "Hay  40  NaNs\n",
            "Los datos tienen  100 filas y 7 columnas\n",
            "Los datos tienen  100 filas y 5 columnas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Ejercicio #3 Reemplazar NaNs por la media de la columna**\n",
        "\n",
        "Dado un dataset, hacer una función que utilizando numpy reemplace los NaNs por la medida de la columna."
      ],
      "metadata": {
        "id": "Mh3oZUBQrtu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos el dataset para el punto 3\n",
        "def cargar():\n",
        "  cam='c3v2.csv'\n",
        "  datos = pd.read_csv('c3v2.csv', sep=';'  , header=None , engine='python')\n",
        "  print('Los datos tienen ',datos.shape[0],'filas y',datos.shape[1],'columnas')\n",
        "  cuantosNan=np.count_nonzero(np.isnan(datos))\n",
        "  print('Hay ',cuantosNan,' NaNs')\n",
        "  return datos\n",
        "\n",
        "def imputar_con_media():\n",
        "  dataset_punto_3=cargar()\n",
        "  print('Las medias son:', dataset_punto_3.mean())\n",
        "  new_dts3=dataset_punto_3.fillna(value=dataset_punto_3.mean())\n",
        "  cuantosNan3=np.count_nonzero(np.isnan(new_dts3))\n",
        "  print('Hay ',cuantosNan3,' NaNs')\n",
        "  print(new_dts3)\n",
        "\n",
        "imputar_con_media()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvhl_Ok6QMM1",
        "outputId": "85d40ea6-4c22-448e-d924-cfeb8b3bacab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los datos tienen  100 filas y 7 columnas\n",
            "Hay  40  NaNs\n",
            "Las medias son: 0    2.271986\n",
            "1    1.284816\n",
            "2    4.184569\n",
            "3    1.103956\n",
            "4   -0.631169\n",
            "5   -3.834794\n",
            "6    1.509312\n",
            "dtype: float64\n",
            "Hay  0  NaNs\n",
            "            0         1          2         3         4          5          6\n",
            "0    3.669506  2.863605   4.184569  2.948632 -0.631169  -9.364512   7.564543\n",
            "1   13.505001  4.482330   4.184569  0.770769 -0.631169  -3.706287  32.866898\n",
            "2   -5.736774 -1.030994   4.184569  0.907981 -0.631169   5.332656 -20.922094\n",
            "3   -0.019325  1.909841   4.184569  0.137427 -0.631169   3.400036   1.433380\n",
            "4    6.079670  1.528345   4.184569  0.746475 -0.631169 -11.486688  11.867943\n",
            "..        ...       ...        ...       ...       ...        ...        ...\n",
            "95   0.029921  5.364063   9.676388  2.644617  1.877694  -7.677102  24.897925\n",
            "96  -1.775782  5.393318   3.854789  3.186040 -1.403002  -3.622327  18.237007\n",
            "97  13.162143  0.164868  12.263580  3.105625 -0.426276  -1.829889  43.654064\n",
            "98   7.060369  4.293074   3.590226 -0.066123 -2.039099  -3.643987  18.831133\n",
            "99 -23.815965  3.424658   1.601140  1.270134 -2.037267   6.164295 -69.318103\n",
            "\n",
            "[100 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Ejercicio #4 Dado un dataset X separarlo en 70/20/10**\n",
        "\n",
        "Como vimos en el ejercicio integrador, en problemas de Machine Learning es fundamental que separemos los datasets de n muestras, en 3 datasets de la siguiente manera:\n",
        "\n",
        "\n",
        "\n",
        "*   **Training dataset:**los datos que utilizaremos para entrenar nuestros modelos. Ej: 70% de las muestras.\n",
        "*   **Validation dataset:** los datos que usamos para calcular métricas y ajistar los hiperparámetros de nuestros modelos. Ej: 20% de las muestras.\n",
        "\n",
        "*   **Testing dataset:**una vez que entrenamos los modelos y encontramos los hiperparámetros óptimos de los mísmos, el testing dataset se lo utiliza para computar las métricas finales de nuestros modelos y analizar cómo se comporta respecto a la generalización. Ej: 10% de las muestras.\n",
        "\n",
        "A partir de utilizar np.random.permutation, hacer un método que dado un dataset, devuelva los 3 datasets como nuevos numpy arrays.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FxO0q8HCsghW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Comenzamos cargando el Dataset\n",
        "def cargar_p4():\n",
        "  cam='c3v2.csv'\n",
        "  datos = pd.read_csv('c3v2.csv', sep=';'  , header=None , engine='python')\n",
        "  #print('Los datos tienen ',datos.shape[0],'filas y',datos.shape[1],'columnas')\n",
        "  cuantosNan=np.count_nonzero(np.isnan(datos))\n",
        "  #print('Hay ',cuantosNan,' NaNs')\n",
        "  return datos\n",
        "\n",
        "#Imputamos los datos faltantes como en el punto 3\n",
        "def imputar_con_media_4():\n",
        "  dataset_punto_4=cargar()\n",
        "  #print('Las medias son:', dataset_punto_4.mean())\n",
        "  new_dts4=dataset_punto_4.fillna(value=dataset_punto_4.mean())\n",
        "  cuantosNan4=np.count_nonzero(np.isnan(new_dts4))\n",
        "  #print('Hay ',cuantosNan4,' NaNs')\n",
        "  return new_dts4\n",
        "\n",
        "datos4=imputar_con_media_4()\n",
        "\n",
        "#Calculamos el número de filas que tiene el dataset\n",
        "numero_de_filas=datos4.shape[0]\n",
        "setenta_porciento=int(np.round(numero_de_filas*0.7,decimals=0))\n",
        "veinte_porciento=int(np.round(numero_de_filas*0.2,decimals=0))\n",
        "diez_porciento=int(np.round(numero_de_filas*0.1,decimals=0))\n",
        "\n",
        "#Calculamos los indices\n",
        "indices=np.random.permutation(len(datos4))\n",
        "\n",
        "datos4[len(datos4.columns)]=indices\n",
        "datos4=datos4.sort_values(7)\n",
        "\n",
        "#Devolvemos las matrices\n",
        "primerDataFrame=datos4.iloc[:setenta_porciento]\n",
        "tercerDataFrame=datos4.iloc[diez_porciento:]\n",
        "segundoDataFrame=datos4.iloc[setenta_porciento:diez_porciento]\n",
        "\n",
        "print(primerDataFrame)\n",
        "print(segundoDataFrame)\n",
        "print(tercerDataFrame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKY7PPnFZUKh",
        "outputId": "659ececf-2c5d-4917-bc70-45276a0f5548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los datos tienen  100 filas y 7 columnas\n",
            "Hay  40  NaNs\n",
            "            0         1          2         3         4          5          6  \\\n",
            "99 -23.815965  3.424658   1.601140  1.270134 -2.037267   6.164295 -69.318103   \n",
            "11  -1.988850 -1.449227   4.184569  0.826902 -0.631169  -5.535351 -18.748564   \n",
            "2   -5.736774 -1.030994   4.184569  0.907981 -0.631169   5.332656 -20.922094   \n",
            "55  -2.800081 -3.078380   8.085855  0.594078 -3.779044 -13.355980 -27.543090   \n",
            "67   3.379928  6.531256  11.611802  2.165750  6.575618  -0.636385  38.866804   \n",
            "..        ...       ...        ...       ...       ...        ...        ...   \n",
            "8   -4.434366  1.919696   4.184569  2.913292 -0.631169  -9.078455 -23.122893   \n",
            "16   3.677814 -5.059008   4.184569 -0.339200 -0.905344   0.267167  -0.027864   \n",
            "41   5.165234  2.731365  -0.808875  2.800402  1.284587   1.032458  24.434100   \n",
            "34   2.390701  1.534878   2.251833  1.121436 -4.215330  -8.385880  -0.254915   \n",
            "37  15.906703  0.517807   5.185552 -0.288054 -0.141758  11.644725  47.892762   \n",
            "\n",
            "     7  \n",
            "99   0  \n",
            "11   1  \n",
            "2    2  \n",
            "55   3  \n",
            "67   4  \n",
            "..  ..  \n",
            "8   65  \n",
            "16  66  \n",
            "41  67  \n",
            "34  68  \n",
            "37  69  \n",
            "\n",
            "[70 rows x 8 columns]\n",
            "Empty DataFrame\n",
            "Columns: [0, 1, 2, 3, 4, 5, 6, 7]\n",
            "Index: []\n",
            "            0         1         2         3         4          5          6  \\\n",
            "32   0.788531 -0.398401  1.575954 -0.730022 -0.684833  -4.947213 -19.703535   \n",
            "52  -5.417610 -0.702466  7.303988  0.463277 -3.841528  -6.262206 -17.512168   \n",
            "62  -1.100399 -1.258699 -2.911920 -0.024175  2.839867  -4.445441 -19.499919   \n",
            "69  10.275338 -0.373827  2.353709  0.491020 -4.655846 -15.575730   8.461701   \n",
            "84   4.890149  0.155043 -0.807802 -0.543062 -2.075848  -1.241657  12.259474   \n",
            "..        ...       ...       ...       ...       ...        ...        ...   \n",
            "21  -2.381354  0.275137  4.184569  0.040952 -4.664043 -11.818938  -2.417554   \n",
            "14 -11.799676 -2.961813  4.184569  0.779812 -0.631169  -3.846574 -66.928472   \n",
            "38  15.587090 -1.759304  6.345152 -0.033522  0.163684  -2.275594  35.318593   \n",
            "86   2.854757  0.156026 -2.012396  3.794472  4.261068  -2.984307   7.611754   \n",
            "40   1.405944 -1.325947  4.455395 -1.388051  0.090125  12.854644   5.778194   \n",
            "\n",
            "     7  \n",
            "32  10  \n",
            "52  11  \n",
            "62  12  \n",
            "69  13  \n",
            "84  14  \n",
            "..  ..  \n",
            "21  95  \n",
            "14  96  \n",
            "38  97  \n",
            "86  98  \n",
            "40  99  \n",
            "\n",
            "[90 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio #5: A partir del dataset de consigna, aplicar los conceptos de regresión lineal.\n",
        "1. Armar una clase para cargar el dataset en un ndarray estructurado, tal como se realizó en el ejercicio 10 de la Clase 1.\n",
        "2.Incluir un método split a la clase para obtener los sets de training y test.\n",
        "3.Crear una clase métrica base y una clase MSE (Error cuadrático medio) que herede de la clase base.\n",
        "4.Crear una clase modelo base y clases regresión lineal y regresión afín que hereden de la primera. Usar los conocimientos teóricos vistos en clase.\n",
        "5.Hacer un fit de las regresiones con los datos de entrenamiento.\n",
        "6.Hacer un predict sobre los datos de test y reportar el MSE en cada caso.\n",
        "7.Graficar la curva obtenida."
      ],
      "metadata": {
        "id": "kT_yItQ0i6f2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrearDataset(object):\n",
        "  #Dado que solo permitimos el uso de un dataset, vamos usar el método new\n",
        "  instancia=None\n",
        "\n",
        "  def  __new__(self,archivo):\n",
        "    if self.instancia!=None:\n",
        "      return instancia\n",
        "    else:\n",
        "      return super(CrearDataset, cls).__new__(CrearDataset,cls)\n",
        "\n",
        "  def __init__(self,nombreArchivo):\n",
        "    pass\n",
        "\n",
        "  def construir():\n"
      ],
      "metadata": {
        "id": "DZ3lMiQ7ok_e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}